{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\joela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\joela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\joela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('reuters')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asian exporters fear damage from u.s.-japan rift\n",
      "  mounting trade friction between the\n",
      "  u.s. and japan has raised fears among many of asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      they told reuter correspondents in asian capitals a u.s.\n",
      "  move against japan might boost protectionist sentiment in the\n",
      "  u.s. and lead to curbs on american imports of their products.\n",
      "      but some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term tokyo's loss might be\n",
      "  their gain.\n",
      "      the u.s. has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of japanese electronics goods on april 17, in\n",
      "  retaliation for japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      unofficial japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports of products hit by the\n",
      "  new taxes.\n",
      "      \"we wouldn't be able to do business,\" said a spokesman for\n",
      "  leading japanese electronics firm matsushita electric\n",
      "  industrial co ltd &lt;mc.t>.\n",
      "      \"if the tariffs remain in place for any length of time\n",
      "  beyond a few months it will mean the complete erosion of\n",
      "  exports (of goods subject to tariffs) to the u.s.,\" said tom\n",
      "  murtha, a stock analyst at the tokyo office of broker &lt;james\n",
      "  capel and co>.\n",
      "      in taiwan, businessmen and officials are also worried.\n",
      "      \"we are aware of the seriousness of the u.s. threat against\n",
      "  japan because it serves as a warning to us,\" said a senior\n",
      "  taiwanese trade official who asked not to be named.\n",
      "      taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
      "  year, 95 pct of it with the u.s.\n",
      "      the surplus helped swell taiwan's foreign exchange reserves\n",
      "  to 53 billion dlrs, among the world's largest.\n",
      "      \"we must quickly open our markets, remove trade barriers and\n",
      "  cut import tariffs to allow imports of u.s. products, if we\n",
      "  want to defuse problems from possible u.s. retaliation,\" said\n",
      "  paul sheen, chairman of textile exporters &lt;taiwan safe group>.\n",
      "      a senior official of south korea's trade promotion\n",
      "  association said the trade dispute between the u.s. and japan\n",
      "  might also lead to pressure on south korea, whose chief exports\n",
      "  are similar to those of japan.\n",
      "      last year south korea had a trade surplus of 7.1 billion\n",
      "  dlrs with the u.s., up from 4.9 billion dlrs in 1985.\n",
      "      in malaysia, trade officers and businessmen said tough\n",
      "  curbs against japan might allow hard-hit producers of\n",
      "  semiconductors in third countries to expand their sales to the\n",
      "  u.s.\n",
      "      in hong kong, where newspapers have alleged japan has been\n",
      "  selling below-cost semiconductors, some electronics\n",
      "  manufacturers share that view. but other businessmen said such\n",
      "  a short-term commercial advantage would be outweighed by\n",
      "  further u.s. pressure to block imports.\n",
      "      \"that is a very short-term view,\" said lawrence mills,\n",
      "  director-general of the federation of hong kong industry.\n",
      "      \"if the whole purpose is to prevent imports, one day it will\n",
      "  be extended to other sources. much more serious for hong kong\n",
      "  is the disadvantage of action restraining trade,\" he said.\n",
      "      the u.s. last year was hong kong's biggest export market,\n",
      "  accounting for over 30 pct of domestically produced exports.\n",
      "      the australian government is awaiting the outcome of trade\n",
      "  talks between the u.s. and japan with interest and concern,\n",
      "  industry minister john button said in canberra last friday.\n",
      "      \"this kind of deterioration in trade relations between two\n",
      "  countries which are major trading partners of ours is a very\n",
      "  serious matter,\" button said.\n",
      "      he said australia's concerns centred on coal and beef,\n",
      "  australia's two largest exports to japan and also significant\n",
      "  u.s. exports to that country.\n",
      "      meanwhile u.s.-japanese diplomatic manoeuvres to solve the\n",
      "  trade stand-off continue.\n",
      "      japan's ruling liberal democratic party yesterday outlined\n",
      "  a package of economic measures to boost the japanese economy.\n",
      "      the measures proposed include a large supplementary budget\n",
      "  and record public works spending in the first half of the\n",
      "  financial year.\n",
      "      they also call for stepped-up spending as an emergency\n",
      "  measure to stimulate the economy despite prime minister\n",
      "  yasuhiro nakasone's avowed fiscal reform program.\n",
      "      deputy u.s. trade representative michael smith and makoto\n",
      "  kuroda, japan's deputy minister of international trade and\n",
      "  industry (miti), are due to meet in washington this week in an\n",
      "  effort to end the dispute.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = [reuters.raw(fileid).lower() for fileid in reuters.fileids()]\n",
    "\n",
    "# Ver el primer documento\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'exporters', 'fear', 'damage', 'from', 'u.s.-japan', 'rift', 'mounting', 'trade', 'friction', 'between', 'the', 'u.s.', 'and', 'japan']\n"
     ]
    }
   ],
   "source": [
    "tokens = [word for doc in documents for word in word_tokenize(doc)]\n",
    "print(tokens[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('het', 'comite'), ('lago', 'agrio'), ('dar', 'es'), ('es', 'salaam'), ('hoare', 'govett'), ('corpus', 'christi'), ('paz', 'estenssoro'), ('corazon', 'aquino'), ('ay', 'expd-e'), ('lear', 'siegler'), ('l.f.', 'rothschild'), ('ranks', 'hovis'), ('abu', 'dhabi'), ('poison', 'pill'), ('hajime', 'tamura'), ('kleinwort', 'benson'), ('ind', 'ttl-f'), ('rjr', 'nabisco'), ('gates', 'learjet'), ('pro', 'forma'), ('margaret', 'thatcher'), ('carter', 'hawley'), ('canary', 'islands'), ('bra', 'kanon'), ('lord', 'abbett'), ('mcdonnell', 'douglas'), ('puerto', 'rico'), ('phelps', 'dodge'), (\"'n\", 'pak'), ('sao', 'paulo'), ('brace', 'jovanovich'), ('karl', 'otto'), ('marlin', 'fitzwater'), ('pizza', 'inn'), ('dean', 'witter'), ('buenos', 'aires'), ('costa', 'rica'), ('del', 'este'), ('king', 'fahd'), ('arturo', 'hernandez'), ('hernandez', 'grisanti'), ('pl', '480'), ('punta', 'del'), ('el', 'nino'), ('optional', 'origin'), ('du', 'pont'), ('drexel', 'burnham'), ('denis', 'bra'), ('hisham', 'nazer'), ('jorio', 'dauster')]\n"
     ]
    }
   ],
   "source": [
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "finder.apply_freq_filter(10)\n",
    "bigramas = finder.nbest(bigram_measures.pmi, n=50)\n",
    "\n",
    "print(bigramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new_york', 'is', 'in', 'united_states', 'of', 'america', '.', 'south_africa', 'and', 'south', 'america', 'are', 'in', 'different', 'continents']\n"
     ]
    }
   ],
   "source": [
    "sentences = [word_tokenize(sent) for sent in sent_tokenize(\"\\n\".join(documents).lower())]\n",
    "sentences = [sent for sent in sentences if len(sent) > 1]\n",
    "\n",
    "collocations = Phrases(sentences=sentences, min_count=10, threshold=0.5, scoring='npmi')\n",
    "to_collocations = Phraser(collocations)\n",
    "\n",
    "sent = 'new york is in united states of america. south africa and south america are in different continents'\n",
    "print(to_collocations[word_tokenize(sent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 bigram      score\n",
      "0                   (+bahia, superior+)  20.560248\n",
      "558                    (justed, adoped)  20.560248\n",
      "548              (invoice, documenting)  20.560248\n",
      "549                         (irv, goss)  20.560248\n",
      "550                    (ismail, salleh)  20.560248\n",
      "551                   (jaap, klootwijk)  20.560248\n",
      "552                (jaimie, villalobos)  20.560248\n",
      "553                     (jamal, hassan)  20.560248\n",
      "554                    (jeoffrey, budd)  20.560248\n",
      "555                      (jesse, helms)  20.560248\n",
      "556                      (joerg, kastl)  20.560248\n",
      "557                 (julien, geertsema)  20.560248\n",
      "559                   (kamal, kharrazi)  20.560248\n",
      "546            (inlcude, 7,507,000-dlr)  20.560248\n",
      "560                  (karim, al-azzawi)  20.560248\n",
      "561                 (karsten, mahlmann)  20.560248\n",
      "562                (katsuhiko, okiyama)  20.560248\n",
      "563                (katsuyuki, okayasu)  20.560248\n",
      "564                       (kaya, erdem)  20.560248\n",
      "565                  (keiichi, udagawa)  20.560248\n",
      "566                      (ken, wikeley)  20.560248\n",
      "567                 (khalifa, al-thani)  20.560248\n",
      "568                        (kheng, hoy)  20.560248\n",
      "569                        (khon, kaen)  20.560248\n",
      "547             (internationale, arabe)  20.560248\n",
      "545                  (iniziativa, meta)  20.560248\n",
      "571                   (koki, chiyojima)  20.560248\n",
      "532                    (hosni, mubarak)  20.560248\n",
      "522                  (hellmuth, klauhs)  20.560248\n",
      "523               (hemileia, vastatrix)  20.560248\n",
      "524               (hemorrhagic, fevers)  20.560248\n",
      "525                    (hendrik, bokma)  20.560248\n",
      "526                         (herb, mee)  20.560248\n",
      "527                   (hero, conserven)  20.560248\n",
      "528                        (heron, cay)  20.560248\n",
      "529                      (hindu, tamil)  20.560248\n",
      "530                 (hiromitsu, sunada)  20.560248\n",
      "531                    (hissene, habre)  20.560248\n",
      "533                       (hu, yaobang)  20.560248\n",
      "544               (iniezione, polimeri)  20.560248\n",
      "534                          (hui, bao)  20.560248\n",
      "535                 (i-style, infantry)  20.560248\n",
      "536                       (il, sole-24)  20.560248\n",
      "537                        (imad, bata)  20.560248\n",
      "538           (import-dependent, elite)  20.560248\n",
      "539              (inaccessible, cabins)  20.560248\n",
      "540  (inadvertently, under-withholding)  20.560248\n",
      "541              (inchon/india, 12,600)  20.560248\n",
      "542              (industriali, riunite)  20.560248\n",
      "543                 (infectious, viral)  20.560248\n"
     ]
    }
   ],
   "source": [
    "# Crear el objeto BigramCollocationFinder\n",
    "collocations = BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Usar BigramAssocMeasures para obtener las puntuaciones de los bigramas\n",
    "scored = collocations.score_ngrams(BigramAssocMeasures().pmi)\n",
    "\n",
    "# Crear un DataFrame con los bigramas y sus puntuaciones\n",
    "df_collocations = pd.DataFrame(scored, columns=[\"bigram\", \"score\"])\n",
    "\n",
    "# Eliminar duplicados y ordenar por puntuaci√≥n\n",
    "df_collocations = df_collocations.drop_duplicates().sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "# Imprimir los primeros 50 bigramas\n",
    "print(df_collocations.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_collocations.save('bigram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\joela/nltk_data', 'c:\\\\Users\\\\joela\\\\Documentos\\\\WorkSpace\\\\Universidad\\\\Semestre 5\\\\14567-Web Avanzada\\\\taller Minar textos\\\\MineriaDeTextos\\\\env\\\\nltk_data', 'c:\\\\Users\\\\joela\\\\Documentos\\\\WorkSpace\\\\Universidad\\\\Semestre 5\\\\14567-Web Avanzada\\\\taller Minar textos\\\\MineriaDeTextos\\\\env\\\\share\\\\nltk_data', 'c:\\\\Users\\\\joela\\\\Documentos\\\\WorkSpace\\\\Universidad\\\\Semestre 5\\\\14567-Web Avanzada\\\\taller Minar textos\\\\MineriaDeTextos\\\\env\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\joela\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
